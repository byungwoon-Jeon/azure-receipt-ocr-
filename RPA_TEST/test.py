# --- ì–´ëŒ‘í„°: íšŒì‚¬ ìŠ¤ë ˆë“œ ìœ í‹¸ìš© (_adapter_execute_worker) ---
def _adapter_execute_worker(params: dict) -> dict:
    """
    idp_utils.run_in_multi_threadìš© ì–´ëŒ‘í„°.
    ì…ë ¥: {"idp_item": dict, "duser_input": dict}
    ì¶œë ¥: execute_workerì˜ ë°˜í™˜ dict
    """
    return execute_worker(params["idp_item"], params["duser_input"])

#
# --- execute: ì•„ì´í…œ ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ ---
def execute(duser_input: dict) -> str:
    logger.info("[ì‹œì‘] extractor.execute (ì•„ì´í…œ ê¸°ë°˜)")

    # 1) ì›Œí‚¹ ê²½ë¡œ ë³‘í•© + í™˜ê²½ ì…‹ì—… (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    try:
        wps = idp_setup_env.initialize_working_paths(script_path.parent)
        duser_input = {**duser_input, **wps}
    except Exception:
        logger.exception("[WARN] working paths ì´ˆê¸°í™” ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")

    vr = validate_required_fields(duser_input)
    if vr["has_error"]:
        ret = {
            "callback_url": None, "req_no": None, "cmd_id": None,
            "has_error": True, "error_message": vr["error_message"], "error_fields": vr["error_fields"],
            "idp_items": []
        }
        logger.warning(f"ì…ë ¥ê°’ ê²€ì¦ ì‹¤íŒ¨: {vr['error_message']}")
        return json.dumps(ret, ensure_ascii=False, indent=2)

    duser_input = das_process_setup(duser_input)

    # 2) DBì—ì„œ ëŒ€ìƒ ë ˆì½”ë“œ ì¡°íšŒ (ì›ë³¸ ìœ ì§€)
    try:
        data_records = query_data_by_date(duser_input)
    except Exception as e:
        logger.exception("[FATAL] DB ì¡°íšŒ ì‹¤íŒ¨")
        ret = {
            "callback_url": None, "req_no": None, "cmd_id": None,
            "has_error": True, "error_message": f"DB ì¡°íšŒ ì‹¤íŒ¨: {e}", "error_fields": None,
            "idp_items": []
        }
        return json.dumps(ret, ensure_ascii=False, indent=2)

    if not data_records:
        ret = {
            "callback_url": None, "req_no": None, "cmd_id": None,
            "has_error": False, "error_message": None, "error_fields": None,
            "idp_items": []
        }
        logger.info("ğŸ“­ ì²˜ë¦¬í•  ë°ì´í„° ì—†ìŒ")
        return json.dumps(ret, ensure_ascii=False, indent=2)

    # 3) (ë©€í‹°ìŠ¤ë ˆë“œ) ì „ì²˜ë¦¬ ëë‚œ ì•„ì´í…œ ìƒì„±
    #    NOTE: generate_idp_items() ì•ˆì—ì„œ run_pre_processë¥¼ ë³‘ë ¬ë¡œ ëŒë ¤ OCR ëŒ€ìƒ ì•„ì´í…œì„ ë§Œë“¤ì–´ì˜¨ë‹¤ëŠ” ì „ì œ
    try:
        from pre_processing import generate_idp_items  # ë„¤ê°€ ë§Œë“  í•¨ìˆ˜
    except Exception:
        # ëª¨ë“ˆ ê²½ë¡œê°€ ë‹¤ë¥´ë©´ ì—¬ê¸° importë§Œ ë§ì¶°ì¤˜
        from pre_pre_process import generate_idp_items  # ì˜ˆë¹„

    idp_items = generate_idp_items(duser_input, data_records)
    if not idp_items:
        ret = {
            "callback_url": None, "req_no": None, "cmd_id": None,
            "has_error": False, "error_message": None, "error_fields": None,
            "idp_items": []
        }
        logger.info("ğŸ“­ ìƒì„±ëœ OCR ëŒ€ìƒ ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤.")
        return json.dumps(ret, ensure_ascii=False, indent=2)

    # 4) (ë©€í‹°ìŠ¤ë ˆë“œ) ì•„ì´í…œ ë‹¨ìœ„ ì›Œì»¤ ì‹¤í–‰: OCR â†’ í›„ì²˜ë¦¬ â†’ DB
    func_params_list = [
        {"idp_item": idp_item, "duser_input": duser_input}
        for idp_item in idp_items
    ]

    results = idp_utils.run_in_multi_thread(
        func=_adapter_execute_worker,
        func_params_list=func_params_list,
    )

    # 5) ê²°ê³¼ ì§‘ê³„ í›„ ë°˜í™˜
    ret = {
        "callback_url": None, "req_no": None, "cmd_id": None,
        "has_error": any(r.get("has_error") for r in results),
        "error_message": None, "error_fields": None,
        "idp_items": results
    }
    logger.info("âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (ì•„ì´í…œ ê¸°ë°˜)")
    return json.dumps(ret, ensure_ascii=False, indent=2)
    
    
    # --- execute_worker: (ì „ì²˜ë¦¬ ì œì™¸) OCR â†’ í›„ì²˜ë¦¬ â†’ DB ---
def execute_worker(idp_item: dict, duser_input: dict) -> dict:
    """
    ì…ë ¥: generate_idp_items()ê°€ ë§Œë“  'ì•„ì´í…œ' (ì „ì²˜ë¦¬ ì™„ë£Œ ìƒíƒœ)
      í•„ìˆ˜ í•„ë“œ ì˜ˆ:
        - FIID, LINE_INDEX, RECEIPT_INDEX, COMMON_YN, GUBUN
        - file_path (OCR ëŒ€ìƒ ê²½ë¡œ)
        - RESULT_CODE, RESULT_MESSAGE (ì „ì²˜ë¦¬ ê²°ê³¼ ì½”ë“œ/ë©”ì‹œì§€; ì„ íƒ)
    ì¶œë ¥: ì²˜ë¦¬ ê²°ê³¼ë¥¼ í¬í•¨í•œ idp_item (has_error, error_message ê°±ì‹  ë“±)
    """
    fiid = idp_item.get("FIID")
    line_idx = idp_item.get("LINE_INDEX")
    rcp_idx = idp_item.get("RECEIPT_INDEX")
    logger.info(f"[ì‹œì‘] execute_worker item={fiid}-{line_idx}-{rcp_idx}")

    # (ì˜µì…˜) ì‹¤í–‰ ì´ë ¥ ì‹œì‘ ê¸°ë¡ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ í˜¸ì¶œ
    # _write_history_start(idp_item, duser_input)

    try:
        # 0) ì „ì²˜ë¦¬ ë‹¨ê³„ ì‹¤íŒ¨ ì•„ì´í…œ ê°€ë“œ (ìˆë‹¤ë©´ ê³§ë°”ë¡œ ì‹¤íŒ¨ ìš”ì•½ ìƒì„±)
        pre_code = str(idp_item.get("RESULT_CODE", "200"))
        if pre_code != "200":
            msg = idp_item.get("RESULT_MESSAGE") or "ì „ì²˜ë¦¬ ì‹¤íŒ¨"
            logger.warning(f"[SKIP] ì „ì²˜ë¦¬ ì‹¤íŒ¨ ì•„ì´í…œ: {fiid}-{line_idx}-{rcp_idx} / {msg}")
            try:
                write_fail_and_insert(
                    duser_input=duser_input,
                    base=idp_item,
                    code=pre_code,
                    message=msg,
                    attach_file=None,
                    receipt_index=idp_item.get("RECEIPT_INDEX"),
                )
            except Exception:
                logger.exception("[WARN] ì‹¤íŒ¨ ìš”ì•½ ê¸°ë¡ ì¤‘ ì˜ˆì™¸ (ì „ì²˜ë¦¬ ì‹¤íŒ¨)")
            idp_item["has_error"] = True
            idp_item["error_message"] = msg
            return idp_item

        # 1) OCR (Azure)
        if run_azure_ocr is None:
            raise RuntimeError("run_azure_ocr í•¨ìˆ˜ import ì‹¤íŒ¨")

        ocr_in = {**idp_item}  # í•„ìš” ì‹œ í•„ë“œ ì¶•ì•½/í™•ì¥ ê°€ëŠ¥
        ocr_out = run_azure_ocr(duser_input, ocr_in)

        if isinstance(ocr_out, dict) and str(ocr_out.get("RESULT_CODE")) in ("AZURE_ERR", "500"):
            msg = ocr_out.get("RESULT_MESSAGE", "Azure OCR ì‹¤íŒ¨")
            logger.warning(f"[ERROR] Azure OCR ì‹¤íŒ¨: {fiid}-{line_idx}-{rcp_idx} / {msg}")
            try:
                write_fail_and_insert(
                    duser_input=duser_input,
                    base=idp_item,
                    code=str(ocr_out.get("RESULT_CODE", "AZURE_ERR")),
                    message=msg,
                    attach_file=None,
                    receipt_index=idp_item.get("RECEIPT_INDEX"),
                )
            except Exception:
                logger.exception("[WARN] ì‹¤íŒ¨ ìš”ì•½ ê¸°ë¡ ì¤‘ ì˜ˆì™¸ (OCR ì‹¤íŒ¨)")
            idp_item["has_error"] = True
            idp_item["error_message"] = msg
            return idp_item

        # 2) í›„ì²˜ë¦¬
        if post_process_and_save is None:
            raise RuntimeError("post_process_and_save í•¨ìˆ˜ import ì‹¤íŒ¨")

        # OCR JSON ê²½ë¡œ ì¶”ì •/ê²°ì •
        azure_dir = duser_input.get("idp_azure_dir") or os.path.join(duser_input["idp_workspace_dir"], "Azure")
        os.makedirs(azure_dir, exist_ok=True)
        try:
            base_name = Path(idp_item.get("file_path") or "").stem or f"{fiid}_{line_idx}_{rcp_idx}"
        except Exception:
            base_name = f"{fiid}_{line_idx}_{rcp_idx}"
        ocr_json_path = os.path.join(azure_dir, f"{base_name}.ocr.json")

        post_json_path = post_process_and_save(
            {**duser_input, "idp_postprocess_dir": duser_input.get("idp_postprocess_dir")},
            {**idp_item, "json_path": ocr_json_path}
        )

        # 3) DB ì €ì¥
        if insert_postprocessed_result is None:
            raise RuntimeError("insert_postprocessed_result í•¨ìˆ˜ import ì‹¤íŒ¨")
        insert_postprocessed_result(post_json_path, duser_input)

        idp_item["has_error"] = False
        idp_item["error_message"] = None
        logger.info(f"[ì„±ê³µ] execute_worker item={fiid}-{line_idx}-{rcp_idx}")

    except Exception as e:
        logger.error(f"[FATAL] execute_worker ì˜ˆì™¸: {e}", exc_info=True)
        idp_item["has_error"] = True
        idp_item["error_message"] = str(e)

    finally:
        # (ì˜µì…˜) ì‹¤í–‰ ì´ë ¥ ì¢…ë£Œ ê¸°ë¡
        # _write_history_end(idp_item)
        logger.info(f"[ì¢…ë£Œ] execute_worker item={fiid}-{line_idx}-{rcp_idx}")

    return idp_item
    
    