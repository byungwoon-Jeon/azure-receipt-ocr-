import os
import json
import re
import logging
import traceback
from datetime import datetime
from typing import Optional

logger = logging.getLogger("POST_PROCESS")


# =========================
# ìŠ¹ì¸ë²ˆí˜¸ ì¶”ì¶œ ìœ í‹¸
# =========================
LOGGER_EXTRACT = logging.getLogger("APPROVAL_EXTRACT")

# ë¼ë²¨ íŒ¨í„´: í•œêµ­ì–´/ì˜ì–´ ë³€í˜•ì„ í­ë„“ê²Œ ì»¤ë²„
LABEL_PATTERN = re.compile(
    r"(?:"
    r"ìŠ¹ì¸\s*(?:ë²ˆí˜¸|NO|ì½”ë“œ)"
    r"|"
    r"Auth(?:orization|entication)?(?:\s*(?:No|Code))?"
    r"|"
    r"Approval\s*(?:No|Number|Code)"
    r")",
    re.IGNORECASE,
)

# ê°’ í›„ë³´: ëŒ€ë¬¸ì/ìˆ«ìì™€ ê³µë°±ì˜ ë¬¶ìŒ(ìµœì¢… ê²€ì¦ì€ ë³„ë„)
VALUE_CHUNK = re.compile(r"[A-Z0-9][A-Z0-9\s]{5,20}", re.IGNORECASE)


def _normalize_and_validate(token: str) -> Optional[str]:
    """
    ê³µë°± ì œê±°/ëŒ€ë¬¸ìí™” í›„ ìŠ¹ì¸ë²ˆí˜¸ ìœ íš¨ì„± ê²€ì‚¬:
    - ê¸¸ì´: 6~12
    - ë¬¸ì: ì˜ë¬¸/ìˆ«ìë§Œ
    - ìˆ«ì ê°œìˆ˜ >= 5  (ìˆœìˆ˜ ì˜ë¬¸ ë°©ì§€: APPROVAL, AUTHORIZATION ë“±)
    """
    if not token:
        return None
    norm = token.replace(" ", "").upper()

    if not (6 <= len(norm) <= 12):
        return None
    if not re.fullmatch(r"[A-Z0-9]+", norm):
        return None

    digit_count = sum(c.isdigit() for c in norm)
    if digit_count < 5:
        return None

    return norm


def extract_approval_no(contents: str) -> Optional[str]:
    """
    ì˜ìˆ˜ì¦ CONTENTSì—ì„œ ìŠ¹ì¸ë²ˆí˜¸ë¥¼ ì¶”ì¶œ.
    - ë¼ë²¨(ìŠ¹ì¸ë²ˆí˜¸/ìŠ¹ì¸ NO/ìŠ¹ì¸ì½”ë“œ/Auth/Authorization/Approval (No|Number|Code) ë“±) í•„ìˆ˜
    - ë¼ë²¨ 'ì´í›„' í…ìŠ¤íŠ¸ì—ì„œ ê°’ íƒìƒ‰ â†’ ì—†ìœ¼ë©´ ë‹¤ìŒ ì¤„ì—ì„œ íƒìƒ‰
    - ê°’ì€ ê³µë°± í¬í•¨ ê°€ëŠ¥ (ì˜ˆ: '1234 5678'), ê²€ì¦ ì‹œ ê³µë°± ì œê±°
    - ì—¬ëŸ¬ ê°œë©´ ì²« ë²ˆì§¸ë§Œ ë°˜í™˜
    """
    if not contents or not isinstance(contents, str):
        return None

    lines = contents.splitlines()
    for i, line in enumerate(lines):
        m = LABEL_PATTERN.search(line)
        if not m:
            continue

        # 1) ê°™ì€ ì¤„: ë¼ë²¨ "ì´í›„" í…ìŠ¤íŠ¸ì—ì„œë§Œ ê°’ íƒìƒ‰ (ë¼ë²¨ ë‹¨ì–´ ì˜¤íƒ ë°©ì§€)
        tail = line[m.end():]
        m_val = VALUE_CHUNK.search(tail)
        if m_val:
            candidate = _normalize_and_validate(m_val.group())
            if candidate:
                return candidate

        # 2) ë‹¤ìŒ ì¤„ì—ì„œ ê°’ íƒìƒ‰
        if i + 1 < len(lines):
            m_next = VALUE_CHUNK.search(lines[i + 1])
            if m_next:
                candidate = _normalize_and_validate(m_next.group())
                if candidate:
                    return candidate

    return None


# =========================
# í•„ë“œ êµ¬ì„± ìœ í‹¸
# =========================
def build_general_fields_from_summary(summary: dict) -> list:
    """
    summary ë”•ì…”ë„ˆë¦¬ë¥¼ general_fields ë°°ì—´ë¡œ ì „ê°œ.
    page_numberëŠ” 1ë¡œ ê³ ì •.
    """
    general_fields = []
    for k, v in summary.items():
        general_fields.append({
            "page_number": 1,
            "name": k,
            "value": v
        })
    return general_fields


TABLE_COLUMNS = [
    "FIID",
    "LINE_INDEX",
    "RECEIPT_INDEX",
    "ITEM_INDEX",
    "ITEM_NAME",
    "ITEM_QTY",
    "ITEM_UNIT_PRICE",
    "ITEM_TOTAL_PRICE",
    "COMMON_YN",
    "CREATE_DATE",
    "UPDATE_DATE",
]


def build_table_fields_from_items(items: list, table_name: str = "table1") -> list:
    """
    items ë¦¬ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ ì»¬ëŸ¼ ìˆœì„œ(TABLE_COLUMNS)ì— ë§ì¶° 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜.
    """
    data_rows = []
    for it in items:
        row = [
            it.get("FIID"),
            it.get("LINE_INDEX"),
            it.get("RECEIPT_INDEX"),
            it.get("ITEM_INDEX"),
            it.get("ITEM_NAME"),
            it.get("ITEM_QTY"),
            it.get("ITEM_UNIT_PRICE"),
            it.get("ITEM_TOTAL_PRICE"),
            it.get("COMMON_YN"),
            it.get("CREATE_DATE"),
            it.get("UPDATE_DATE"),
        ]
        data_rows.append(row)

    table_obj = {
        "table_name": table_name,
        "columns": TABLE_COLUMNS[:],
        "data": data_rows,
        "data_length": len(data_rows),
    }
    return [table_obj]


# =========================
# ë©”ì¸ í›„ì²˜ë¦¬ í•¨ìˆ˜
# =========================
def post_process_and_save(duser_input: dict, record: dict) -> str:
    """
    Azure OCR ê²°ê³¼ JSON ë°ì´í„°ë¥¼ í›„ì²˜ë¦¬í•˜ì—¬ ìš”ì•½(summary) ì •ë³´ì™€ í•­ëª©(item) ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ ,
    í›„ì²˜ë¦¬ JSON(result_json)ì— general_fields / table_fieldsë¥¼ ì¶”ê°€í•˜ì—¬ ì €ì¥.
    ë˜í•œ OCR ì›ë³¸(data)ì„ mongo_dataìš©ìœ¼ë¡œ ë³„ë„ ì €ì¥í•˜ë©´ì„œ, ë™ì¼í•œ general_fields / table_fieldsë„ ì¶”ê°€í•œë‹¤.

    ì…ë ¥:
    - duser_input (dict): í•„ìˆ˜í‚¤
        - postprocess_output_dir: í›„ì²˜ë¦¬ JSON ì €ì¥ í´ë”
        - error_json_dir: ì—ëŸ¬ JSON ì €ì¥ í´ë”(ì˜µì…˜, ê¸°ë³¸ ./error_json)
        - mongo_output_dir: OCR ì›ë³¸ì„ ì¦ê°• ì €ì¥í•  í´ë”(ì˜µì…˜, ê¸°ë³¸ ./mongo_data)
    - record (dict): í•„ìˆ˜í‚¤
        - json_path, FIID, LINE_INDEX, RECEIPT_INDEX, COMMON_YN
        - (ì„ íƒ) CONTENTS: ìŠ¹ì¸ë²ˆí˜¸ìš© ì›ë¬¸

    ë°˜í™˜:
    - str: ìƒì„±ëœ í›„ì²˜ë¦¬ ê²°ê³¼ JSON íŒŒì¼ì˜ ê²½ë¡œ
    """
    logger.info("[ì‹œì‘] post_process_and_save")

    try:
        # í•„ìˆ˜ ì…ë ¥ê°’ ê²€ì‚¬
        assert "postprocess_output_dir" in duser_input, "[ERROR] 'postprocess_output_dir' ë¯¸ì§€ì •"
        for key in ["json_path", "FIID", "LINE_INDEX", "RECEIPT_INDEX", "COMMON_YN"]:
            assert key in record, f"[ERROR] '{key}' í•„ë“œ ì—†ìŒ"

        json_path = record["json_path"]
        output_dir = duser_input["postprocess_output_dir"]
        mongo_output_dir = duser_input.get("mongo_output_dir", "./mongo_data")
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(mongo_output_dir, exist_ok=True)

        if not os.path.exists(json_path):
            raise FileNotFoundError(f"OCR JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {json_path}")

        with open(json_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # Form Recognizer í‘œì¤€ êµ¬ì¡° ê°€ì •
        doc = data.get("analyzeResult", {}).get("documents", [{}])[0]
        fields = doc.get("fields", {}) if isinstance(doc, dict) else {}

        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        fiid = record["FIID"]
        line_index = record["LINE_INDEX"]
        receipt_index = record["RECEIPT_INDEX"]
        common_yn = record["COMMON_YN"]
        attach_file = record.get("ATTACH_FILE")
        gubun = record.get("GUBUN")

        # ìš”ì•½ ì˜ì—­
        summary = {
            "FIID": fiid,
            "LINE_INDEX": line_index,
            "RECEIPT_INDEX": receipt_index,
            "COMMON_YN": common_yn,
            "GUBUN": gubun,
            "ATTACH_FILE": attach_file,
            "COUNTRY": fields.get("CountryRegion", {}).get("valueCountryRegion"),
            "RECEIPT_TYPE": fields.get("MerchantCategory", {}).get("valueString"),
            "MERCHANT_NAME": fields.get("MerchantName", {}).get("valueString"),
            "MERCHANT_PHONE_NO": fields.get("MerchantPhoneNumber", {}).get("valueString"),
            "DELIVERY_ADDR": None,
            "TRANSACTION_DATE": fields.get("TransactionDate", {}).get("valueDate"),
            "TRANSACTION_TIME": fields.get("TransactionTime", {}).get("valueTime"),
            "TOTAL_AMOUNT": str(fields.get("Total", {}).get("valueCurrency", {}).get("amount")),
            "SUMTOTAL_AMOUNT": str(fields.get("Subtotal", {}).get("valueCurrency", {}).get("amount")),
            "TAX_AMOUNT": str(fields.get("TotalTax", {}).get("valueCurrency", {}).get("amount")),
            "BIZ_NO": None,
            "APPROVAL_NO": None,   # ìŠ¹ì¸ë²ˆí˜¸ ìë¦¬
            "RESULT_CODE": 200,
            "RESULT_MESSAGE": "SUCCESS",
            "CREATE_DATE": now_str,
            "UPDATE_DATE": now_str
        }

        # í’ˆëª© ë¦¬ìŠ¤íŠ¸
        item_list = []
        items_field = fields.get("Items", {})
        if isinstance(items_field, dict) and "valueArray" in items_field:
            for idx, item in enumerate(items_field["valueArray"], start=1):
                obj = item.get("valueObject", {}) if item else {}
                item_list.append({
                    "FIID": fiid,
                    "LINE_INDEX": line_index,
                    "RECEIPT_INDEX": receipt_index,
                    "ITEM_INDEX": idx,
                    "ITEM_NAME": obj.get("Description", {}).get("valueString"),
                    "ITEM_QTY": str(obj.get("Quantity", {}).get("valueNumber")) if obj.get("Quantity") else None,
                    "ITEM_UNIT_PRICE": str(obj.get("Price", {}).get("valueCurrency", {}).get("amount")) if obj.get("Price") else None,
                    "ITEM_TOTAL_PRICE": str(obj.get("TotalPrice", {}).get("valueCurrency", {}).get("amount")) if obj.get("TotalPrice") else None,
                    "CONTENTS": json.dumps(obj, ensure_ascii=False),
                    "COMMON_YN": common_yn,
                    "CREATE_DATE": now_str,
                    "UPDATE_DATE": now_str
                })

        # âœ… ìŠ¹ì¸ë²ˆí˜¸ ì¶”ì¶œ: recordì— ì´ë¯¸ ë“¤ì–´ìˆëŠ” CONTENTSë§Œ ì‚¬ìš© (DB ì—…ë°ì´íŠ¸ëŠ” í•˜ì§€ ì•ŠìŒ)
        contents_src = record.get("CONTENTS")
        if contents_src:
            approval_no = extract_approval_no(contents_src)
            if approval_no:
                summary["APPROVAL_NO"] = approval_no

        # ===== êµ¬ì¡° ì¶”ê°€: general_fields / table_fields =====
        general_fields = build_general_fields_from_summary(summary)
        table_fields = build_table_fields_from_items(item_list, table_name="table1")

        # ===== í›„ì²˜ë¦¬ ê²°ê³¼ JSON ì €ì¥ (êµ¬ì¡° ì¶”ê°€ í¬í•¨) =====
        result_json = {
            "summary": summary,
            "items": item_list,
            "general_fields": general_fields,
            "table_fields": table_fields,
        }

        output_filename = f"{fiid}_{line_index}_{receipt_index}_post.json"
        output_path = os.path.join(output_dir, output_filename)
        with open(output_path, "w", encoding="utf-8") as out_f:
            json.dump(result_json, out_f, ensure_ascii=False, indent=2)

        # ===== OCR ì›ë³¸ + êµ¬ì¡° ì¶”ê°€í•´ì„œ mongo_dataë¡œ ë³„ë„ ì €ì¥ =====
        mongo_doc = dict(data)  # ì–•ì€ ë³µì‚¬(ì›ë³¸ ë³´ì¡´)
        mongo_doc["general_fields"] = general_fields
        mongo_doc["table_fields"] = table_fields

        mongo_filename = f"{fiid}_{line_index}_{receipt_index}_mongo.json"
        mongo_path = os.path.join(mongo_output_dir, mongo_filename)
        with open(mongo_path, "w", encoding="utf-8") as mf:
            json.dump(mongo_doc, mf, ensure_ascii=False, indent=2)

        logger.info(f"[ì™„ë£Œ] í›„ì²˜ë¦¬ ì €ì¥: {output_path}")
        logger.info(f"[ì™„ë£Œ] mongo_data ì €ì¥: {mongo_path}")
        logger.info("[ì¢…ë£Œ] post_process_and_save")
        return output_path

    except Exception as e:
        logger.error(f"[ERROR] í›„ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        traceback.print_exc()

        error_dir = duser_input.get("error_json_dir", "./error_json")
        os.makedirs(error_dir, exist_ok=True)
        # ì—ëŸ¬ JSON íŒŒì¼ ê²½ë¡œ
        fiid = record.get("FIID", "UNKNOWN")
        line_index = record.get("LINE_INDEX", "NA")
        error_path = os.path.join(error_dir, f"fail_{fiid}_{line_index}.json")

        now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        error_summary = {
            "FIID": record.get("FIID"),
            "LINE_INDEX": record.get("LINE_INDEX"),
            "RECEIPT_INDEX": record.get("RECEIPT_INDEX"),
            "COMMON_YN": record.get("COMMON_YN"),
            "GUBUN": record.get("GUBUN"),
            "ATTACH_FILE": record.get("ATTACH_FILE"),
            "COUNTRY": None, "RECEIPT_TYPE": None, "MERCHANT_NAME": None, "MERCHANT_PHONE_NO": None,
            "DELIVERY_ADDR": None, "TRANSACTION_DATE": None, "TRANSACTION_TIME": None,
            "TOTAL_AMOUNT": None, "SUMTOTAL_AMOUNT": None, "TAX_AMOUNT": None, "BIZ_NO": None,
            "APPROVAL_NO": None,
            "RESULT_CODE": "POST_ERR",
            "RESULT_MESSAGE": str(e),
            "CREATE_DATE": now_str,
            "UPDATE_DATE": now_str
        }

        with open(error_path, "w", encoding="utf-8") as f:
            json.dump({"summary": error_summary, "items": [], "general_fields": [], "table_fields": []},
                      f, ensure_ascii=False, indent=2)

        return error_path


if __name__ == "__main__":
    from pprint import pprint

    # âœ… í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
    duser_input = {
        "postprocess_output_dir": "./test_postprocess_json",  # í›„ì²˜ë¦¬ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜
        "error_json_dir": "./test_error_json",               # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ JSON ì €ì¥ ìœ„ì¹˜
        "mongo_output_dir": "./test_mongo_data",             # OCR ì›ë³¸+êµ¬ì¡° ì €ì¥ ìœ„ì¹˜
    }

    # âœ… í…ŒìŠ¤íŠ¸ìš© OCR JSONì„ ê°€ì§„ record
    record = {
        "FIID": "TEST001",
        "LINE_INDEX": 1,
        "RECEIPT_INDEX": 1,
        "COMMON_YN": 0,
        "GUBUN": "Y",
        "ATTACH_FILE": "https://dummy-url/receipt.png",
        "json_path": "./test_ocr_json/sample_receipt.ocr.json",  # ì‹¤ì œ OCR JSON ê²½ë¡œë¡œ êµì²´
        # CONTENTSê°€ DB ì›ë¬¸ì´ë¼ë©´ ì—¬ê¸° ë„£ì–´ í…ŒìŠ¤íŠ¸
        "CONTENTS": "ìŠ¹ì¸ë²ˆí˜¸\n1234 5678\në‹¤ë¥¸ ë‚´ìš©ë“¤...\nAuthorization code:\n213511"
    }

    try:
        print("ğŸ§ª post_process_and_save() í…ŒìŠ¤íŠ¸ ì‹œì‘")
        output_path = post_process_and_save(duser_input, record)

        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ: {output_path}")
        with open(output_path, "r", encoding="utf-8") as f:
            result_data = json.load(f)
            print("\nğŸ“„ ìš”ì•½ ë°ì´í„°:")
            pprint(result_data["summary"])
            print("\nğŸ§© general_fields (ì¼ë¶€):")
            pprint(result_data["general_fields"][:5])
            print("\nğŸ“¦ table_fields schema:")
            pprint(result_data["table_fields"][0]["columns"])
            print("\nğŸ“Š table_fields rows (ìµœëŒ€ 2ê°œ):")
            pprint(result_data["table_fields"][0]["data"][:2])

        # mongo_data íŒŒì¼ë„ í™•ì¸
        mongo_path = os.path.join(duser_input["mongo_output_dir"], "TEST001_1_1_mongo.json")
        if os.path.exists(mongo_path):
            print(f"\nğŸ—„ mongo_data íŒŒì¼: {mongo_path}")
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")