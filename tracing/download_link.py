import os
import requests
from urllib.parse import urlparse
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

def _download_single_file(url: str, save_dir: str) -> tuple:
    """
    ë‚´ë¶€ìš©: ë‹¨ì¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜
    return: (success(bool), saved_path(str), error(str or None), url)
    """

    try:
        os.makedirs(save_dir, exist_ok=True)

        # [HOOK] í´ë” ìƒì„± ì‹œ ë¡œê¹… ê°€ëŠ¥
        # ex) logging.info(f"ì €ì¥ í´ë” ìƒì„±: {save_dir}")

        filename = os.path.basename(urlparse(url).path)
        ext = os.path.splitext(filename)[-1] or ".jpg"
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_filename = f"image_{timestamp}{ext}"
        save_path = os.path.join(save_dir, new_filename)

        # [HOOK] ë‹¤ìš´ë¡œë“œ ì‹œì‘ ë¡œê·¸
        # ex) logging.info(f"ë‹¤ìš´ë¡œë“œ ì‹œì‘ | URL: {url} â†’ {save_path}")

        response = requests.get(url, timeout=15)
        response.raise_for_status()
        with open(save_path, "wb") as f:
            f.write(response.content)

        # [HOOK] ë‹¤ìš´ë¡œë“œ ì„±ê³µ ë¡œê·¸
        # ex) logging.info(f"ë‹¤ìš´ë¡œë“œ ì„±ê³µ | ì €ì¥ ê²½ë¡œ: {save_path}")

        return True, save_path, None, url

    except Exception as e:
        # [HOOK] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ë¡œê·¸
        # ex) logging.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ | URL: {url} | ì—ëŸ¬: {e}")
        return False, None, str(e), url


def download_from_links(input_dict: dict) -> str:
    """
    ğŸ“¦ ë‹¤ìš´ë¡œë“œ ìœ í‹¸ í•¨ìˆ˜ (ë‹¨ì¼/ë‹¤ì¤‘ ìë™ ë¶„ê¸°)
    """
    save_dir = input_dict.get("save_dir")
    urls = input_dict.get("urls")

    # [HOOK] ì…ë ¥ê°’ í™•ì¸ ë¡œê·¸
    # ex) logging.info(f"ì…ë ¥ê°’ í™•ì¸ | save_dir={save_dir} | urls={urls}")

    if not save_dir or not urls:
        return "success=false; saved_path=; error=ì…ë ¥ê°’ì— 'save_dir' ë˜ëŠ” 'urls'ê°€ ì—†ìŠµë‹ˆë‹¤"

    if isinstance(urls, str):
        urls = [urls]

    if len(urls) == 1:
        # [HOOK] ë‹¨ì¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘ ë¡œê·¸
        # ex) logging.info("ë‹¨ì¼ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬ ì‹œì‘")

        success, saved_path, error, _ = _download_single_file(urls[0], save_dir)

        # [HOOK] ë‹¨ì¼ ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ë¡œê·¸
        # ex) logging.info(f"ê²°ê³¼ | success={success}, saved_path={saved_path}, error={error}")

        return f"success={str(success).lower()}; saved_path={saved_path or ''}; error={error or ''}"

    else:
        # [HOOK] ë©€í‹° ë‹¤ìš´ë¡œë“œ ì‹œì‘ ë¡œê·¸
        # ex) logging.info(f"ë‹¤ì¤‘ ë‹¤ìš´ë¡œë“œ ì‹œì‘ | ë§í¬ ìˆ˜: {len(urls)}")

        results = []
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = [executor.submit(_download_single_file, url, save_dir) for url in urls]
            for future in futures:
                results.append(future.result())

        success_count = sum(1 for r in results if r[0])
        saved_paths = [r[1] for r in results if r[0]]
        failed_urls = [r[3] for r in results if not r[0]]

        # [HOOK] ë©€í‹° ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ìš”ì•½ ë¡œê·¸
        # ex) logging.info(f"ë‹¤ì¤‘ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ | ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {len(failed_urls)}")

        return (
            f"success={success_count}/{len(urls)}; "
            f"saved_paths={saved_paths}; "
            f"failed_urls={failed_urls}"
        )
